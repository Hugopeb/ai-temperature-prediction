{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73457330",
   "metadata": {},
   "source": [
    "# Data Cleaning and Setup\n",
    "\n",
    "This notebook marks the beginning of my meteorological forecasting project during my internship at **MeteoGalicia**. My first task was to create a clean and well-structured dataset based on the raw data files provided by my tutors. This step was essential to ensure that the dataset was ready for model training and further analysis.\n",
    "\n",
    "All data processing and model training were performed remotely on the **CESGA** (*Centro Europeo de Supercomputación de Galicia*) high-performance computing cluster.\n",
    "\n",
    "To access CESGA, I first established a secure **VPN** connection using the snx command-line utility, which allowed CESGA to identify and authorize my device. Once connected, I used **SSH** to access the cluster and standard Bash commands to navigate directories, manage files, and execute Python scripts.\n",
    "\n",
    "Below is the basic process I used to connect to CESGA via SSH after the VPN was successfully established."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4d6083",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "sudo ./snx -s pasarela.cesga.es -u uscfphpb\n",
    "ssh uscfphpb@ft.cesga.es"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59425b0d",
   "metadata": {},
   "source": [
    "Once connected to CESGA facilites, I started polishing the data I had at my disposal. To create a comprehensive dataset, I had to merge multiple files containing hour-by-hour data from a meteorological model alongside observational data collected from various weather stations. Each file represented a different time period or data source, so careful alignment was required to synchronize timestamps and ensure consistency. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0836430",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd GitHub/dataset/\n",
    "tar -xvzf estaciones.tar.gz\n",
    "tar -xvzf wrfout.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab30ec7",
   "metadata": {},
   "source": [
    "2008 to 2025 .csv files contain hour-by-hour observational data from different stations across Galicia whereas wrfout files contain predictions made by the WRF (Weather Research and Forecasting Model) sorted by hour as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7662760",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "csv_files = sorted(glob.glob(\"GitHub/dataset/20*.csv\"))\n",
    "\n",
    "df_combined = pd.concat([pd.read_csv(file) for file in csv_files], ignore_index=True)\n",
    "df_combined.to_csv('Observational_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6089a178",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd \n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "\n",
    "csv_files = sorted(glob.glob(\"GitHub/dataset/wrfout*.csv\"))\n",
    "all_data = []\n",
    "\n",
    "for file in csv_files:\n",
    "    # Extract date from filename\n",
    "    date_str = os.path.basename(file).split('_')[2]  # 'YYYYMMDD' format\n",
    "    base_datetime = datetime.strptime(date_str, \"%Y%m%d\")\n",
    "    \n",
    "    df = pd.read_csv(file)\n",
    "    \n",
    "    # Add hour sequence and datetime column\n",
    "    df['hour'] = list(range(24)) * (len(df) // 24)\n",
    "    df['datetime'] = df['hour'].apply(lambda h: base_datetime + timedelta(hours=h))\n",
    "    \n",
    "    df.drop(columns='hour', inplace=True)\n",
    "    all_data.append(df)\n",
    "\n",
    "# Combine all files\n",
    "merged_df = pd.concat(all_data, ignore_index=True)\n",
    "# Save to CSV\n",
    "merged_df.to_csv(\"WRF.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff909ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "obs = pd.read_csv('Observational_data.csv')\n",
    "obs['datetime'] = obs['fecha'] ; obs['id'] = obs['estacion']\n",
    "\n",
    "wrf = pd.read_csv('WRF.csv')\n",
    "wrf['datetime'] = wrf['Time']; wrf['id'] = wrf['estacion'] \n",
    "\n",
    "# Perform the merge on both keys\n",
    "merged = pd.merge(wrf, obs[['TA','id','datetime']], on=[\"id\", \"datetime\"], how=\"inner\")\n",
    "merged.to_csv(\"DATA.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80851da6",
   "metadata": {},
   "source": [
    "## Additional variables\n",
    "\n",
    "The available data was sufficient to begin developing a model capable of forecasting temperature. However, we identified several missing parameters that could significantly impact the model’s accuracy and decided they were worth adding to our initial dataset. One of these was the percentage of sea surrounding a given location. Although Galicia is not a large region, its weather varies considerably from place to place, which makes our task more challenging. The Atlantic Ocean acts as a thermal reservoir, helping to stabilize coastal temperatures, but its influence decreases as we move inland. We believed that including a parameter representing the sea percentage around each point could noticeably improve the model’s accuracy.\n",
    "\n",
    "In addition to this, we decided to incorporate the latitude and longitude of each location, as well as two variables to represent the hour of the day and the day of the year. Because daily and yearly weather patterns follow periodic cycles, simply providing the model with a numeric hour (e.g., 00:00 to 23:00) or day of the year (1 to 365) would not effectively capture this cyclical nature. To address this, we included two periodic functions: one with a period of 24 hours and another with a period of 365 days, allowing the values to return smoothly to their starting point after a full day or year. This is a common and effective practice in meteorological modeling."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VENV",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
